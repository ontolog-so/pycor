{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Trainer\n",
      "Init DocResolver\n",
      "Loading Model from ../../output/7000/model/\n",
      "Load  ../../output/7000/model//heads.csv   소요시간: 0.841\n",
      "Load  ../../output/7000/model//tails.csv   소요시간: 0.009\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import pycor \n",
    "from pycor import utils, korlang\n",
    "\n",
    "stopwatch = utils.StopWatch()\n",
    "\n",
    "\n",
    "model_size = 7000\n",
    "outputpath = \"../../output/\" + str(model_size) + \"/\"\n",
    "model_path = outputpath + \"model/\"\n",
    "\n",
    "pycor.loadmodel(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3959 files\n"
     ]
    }
   ],
   "source": [
    "def listfiles(path):\n",
    "    result_arr = []\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in filenames:\n",
    "        full_filename = os.path.join(path, filename)\n",
    "        result_arr.append(full_filename)\n",
    "    return result_arr\n",
    "    \n",
    "files = []\n",
    "files.extend( listfiles('../../data/wiki2') )\n",
    "files.extend( listfiles('../../data/wiki') )\n",
    "files.extend( listfiles('../samples/news') )\n",
    "files.extend( listfiles('../../data/news') )\n",
    "files.extend( listfiles('../../data/blotter') )\n",
    "files.extend( listfiles('../../data/zdnet') )\n",
    "files.extend( listfiles('../../data/ciobiz') )\n",
    "files.extend( listfiles('../../data/NP') )\n",
    "\n",
    "print (len(files), \"files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  70  Docs:  2s.312ms. ( 2,311 ms.)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "yeTags = set(['EFN'])\n",
    "\n",
    "def gettail(word):\n",
    "    if word.bestpair:\n",
    "#         return word.bestpair.tags\n",
    "        return word.bestpair.tail.text\n",
    "    return 'X'\n",
    "\n",
    "def gettag(word):\n",
    "    if word.bestpair:\n",
    "        return word.bestpair.tags\n",
    "    return 'X'\n",
    "\n",
    "def gethead(word):\n",
    "    if word.bestpair:\n",
    "        return word.bestpair.head.text\n",
    "    return 'X'\n",
    "\n",
    "\n",
    "yheadsMap = {}\n",
    "ytailsMap = {}\n",
    "ytagsMap = {}\n",
    "\n",
    "def handleHaed(index, word, words):\n",
    "    yset = yheadsMap.get(word.bestpair.head)\n",
    "    if yset is None:\n",
    "        yset = []\n",
    "        yheadsMap[word.bestpair.head] = yset\n",
    "\n",
    "    if index > 1:\n",
    "        yset.append( [gethead(words[index-1]),gethead(words[index-2])])\n",
    "    else:\n",
    "        yset.append( [gethead(words[index-1])] )\n",
    "        \n",
    "def handleTag(index, word, words):\n",
    "    yset = ytagsMap.get(word.bestpair.head)\n",
    "    if yset is None:\n",
    "        yset = []\n",
    "        ytagsMap[word.bestpair.head] = yset\n",
    "    if index > 1:\n",
    "        yset.append( [gettag(words[index-1]),gettag(words[index-2])])\n",
    "    else:\n",
    "        yset.append( [gettag(words[index-1])] )\n",
    "                \n",
    "def handleTail(index, word, words):\n",
    "    yset = ytailsMap.get(word.bestpair.head)\n",
    "    if yset is None:\n",
    "        yset = []\n",
    "        ytailsMap[word.bestpair.head] = yset\n",
    "    if index > 1:\n",
    "        yset.append( [gettail(words[index-1]),gettail(words[index-2])])\n",
    "    else:\n",
    "        yset.append( [gettail(words[index-1])] )\n",
    "        \n",
    "def analyzeYongEon(file):\n",
    "    sentence_array, words_array = pycor.readfile(file)\n",
    "    \n",
    "    for words in words_array:\n",
    "        for index, word in enumerate(words):\n",
    "            if word.bestpair and len(yeTags & set(word.bestpair.tags))>0 and word.text.endswith('다'):\n",
    "                handleHaed(index, word, words)\n",
    "                handleTail(index, word, words)\n",
    "                handleTag(index, word, words)\n",
    "\n",
    "\n",
    "def writeFile(path, yMap):\n",
    "    with open(path, 'w', encoding='utf-8') as file :\n",
    "        writer = csv.writer(file)\n",
    "        for head, tags in yMap.items():\n",
    "            headText = head.text\n",
    "            for tag in tags:\n",
    "                row = [headText]\n",
    "                row.extend(tag)\n",
    "                writer.writerow(row)\n",
    "        file.close()\n",
    "                         \n",
    "stopwatch.start()\n",
    "\n",
    "docsize = 70\n",
    "\n",
    "for file in files[:docsize]:\n",
    "    if file.endswith(\".txt\"):\n",
    "        analyzeYongEon(file)\n",
    "\n",
    "print(\"Loading \",docsize,\" Docs: \" , stopwatch.secmilli() , \"(\", stopwatch.millisecstr(), \"ms.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1540\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "# yheadsMap \n",
    "# ytailsMap  \n",
    "# ytagsMap  \n",
    "\n",
    "def fill(ylist, ymap):\n",
    "    for head, tags in ymap.items():\n",
    "        headText = head.text\n",
    "        for tag in tags:\n",
    "            row = [headText]\n",
    "            row.extend(tag)\n",
    "            ylist.append(row) \n",
    "        \n",
    "tailsList = []\n",
    "tagsList = []\n",
    "\n",
    "fill(tailsList,ytailsMap)\n",
    "fill(tagsList,ytagsMap)\n",
    "\n",
    "josaYMap = {}\n",
    "matrix = []\n",
    "\n",
    "for index in range(len(tailsList)):\n",
    "    tail = tailsList[index]\n",
    "    tag = tagsList[index]\n",
    "    \n",
    "    text = tail[0]\n",
    "    row = [text]\n",
    "    row.extend(tail[1:])\n",
    "    \n",
    "    josaKey = ''\n",
    "    for tags in tag[1:]:\n",
    "        tagsStr = \"+\".join(tags)\n",
    "        row.append(tagsStr)\n",
    "        josaKey += \"::\"\n",
    "        for t in tags:\n",
    "            if t.startswith(\"J\"):\n",
    "                josaKey += \"+\" + t\n",
    "    \n",
    "    ymap = josaYMap.get(josaKey)\n",
    "    if ymap is None:\n",
    "        ymap = {}\n",
    "        josaYMap[josaKey] = ymap\n",
    "    \n",
    "    count = ymap.get(text)\n",
    "    if count is None:\n",
    "        count = 0\n",
    "    \n",
    "    count += 1\n",
    "    ymap[text] = count\n",
    "    \n",
    "    matrix.append(row)\n",
    "\n",
    "    \n",
    "def writeTailTagsFile(path, tailTagsList):\n",
    "    with open(path, 'w', encoding='utf-8') as file :\n",
    "        writer = csv.writer(file)\n",
    "        for row in tailTagsList:\n",
    "            writer.writerow(row)\n",
    "                \n",
    "        file.close()\n",
    "        \n",
    "outputpath = \"../../output/\" + str(docsize) + \"/\"\n",
    "\n",
    "writeFile(outputpath+'/yongeon-heads.csv',yheadsMap)\n",
    "# writeFile(outputpath+'/yongeon-tails.csv',ytailsMap)\n",
    "# writeFile(outputpath+'/yongeon-tags.csv',ytagsMap)\n",
    "\n",
    "\n",
    "writeTailTagsFile(outputpath+'/yongeon-tails-tags.csv',matrix)\n",
    "\n",
    "print(len(matrix))\n",
    "\n",
    "print(len(josaYMap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycor.res import CollocationResolver\n",
    "import pycor.speechmodel as sm \n",
    "\n",
    "resolver = CollocationResolver()\n",
    "pycor.addresolver(resolver)\n",
    "\n",
    "def gettext(word, islast=False):\n",
    "    if type(word) is sm.Sentence :\n",
    "        if(word.senttype == sm.SENTENCE_TYPE_EQUIV):\n",
    "            return word.text()\n",
    "        else:\n",
    "            return word.text()\n",
    "    else:\n",
    "        if islast and word.bestpair:\n",
    "            return word.bestpair.head.text\n",
    "        else:\n",
    "            return word.text\n",
    "            \n",
    "\n",
    "sentence_array, words_array = pycor.readfile('../samples/docs/economics1.txt')\n",
    "\n",
    "ngrams = {}\n",
    "\n",
    "for sentence in sentence_array:\n",
    "    for index in range(1, len(sentence.words)-1):\n",
    "        first = gettext(sentence.words[index-1])\n",
    "        second = gettext(sentence.words[index])\n",
    "        second2 = gettext(sentence.words[index], True)\n",
    "        third = gettext(sentence.words[index+1], True)\n",
    "        \n",
    "        bigram = ' '.join([first,second2])\n",
    "        trigram = ' '.join([first,second,third])\n",
    "        \n",
    "        bigramCnt = ngrams.get(bigram)\n",
    "        if bigramCnt:\n",
    "            bigramCnt = bigramCnt +1\n",
    "        else:\n",
    "            bigramCnt = 1\n",
    "        ngrams[bigram] = bigramCnt\n",
    "        \n",
    "        trigramCnt = ngrams.get(trigram)\n",
    "        if trigramCnt:\n",
    "            trigramCnt = bigramCnt +1\n",
    "        else:\n",
    "            trigramCnt = 1\n",
    "        ngrams[trigram] = trigramCnt\n",
    "#         ngrams[bigram] = [sentence.words[index-1], sentence.words[index]]\n",
    "#         ngrams[trigram] = [sentence.words[index-1], sentence.words[index],sentence.words[index+1]]\n",
    "#         print(first, second , third )\n",
    "\n",
    "# for key, cnt in ngrams.items():\n",
    "#     if cnt > 1:\n",
    "#         print(key,cnt)\n",
    "\n",
    "# for colloc in pycor.getmodel().collocations.values():\n",
    "#     print(colloc, colloc.frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in files[:400]:\n",
    "#     if file.endswith(\".txt\"):\n",
    "#         pycor.readfile(file)\n",
    "        \n",
    "\n",
    "# print( len(pycor.getmodel().collocations))\n",
    "# for colloc in pycor.getmodel().collocations.values():\n",
    "#     if colloc.frequency > 3:\n",
    "#         print(colloc, colloc.frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pycor.readfile('../samples/news/new1_hani.txt')\n",
    "\n",
    "# for colloc in pycor.getmodel().collocations.values():\n",
    "#     print(colloc, colloc.frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save  ../../output/70//yongeon.csv   소요시간: 0.025\n"
     ]
    }
   ],
   "source": [
    "from pycor.res import yongeonresolver as yr\n",
    "\n",
    "yongeonResolver = yr.YongeonResolver()\n",
    "pycor.addresolver(yongeonResolver)\n",
    "\n",
    "for file in files[:100]:\n",
    "    if file.endswith(\".txt\"):\n",
    "        pycor.readfile(file)\n",
    "\n",
    "yongeonResolver.writemap(outputpath + \"/yongeon.csv\")\n",
    "# for head, pmap in yongeonResolver.phraseMap.items():\n",
    "#     print(head)\n",
    "    \n",
    "#     for text, m in pmap.items():\n",
    "#         print('  ',text)\n",
    "#         for w in m:\n",
    "#             if w.bestpair:\n",
    "#                 print('    ', w.bestpair.tags, end=\":\")\n",
    "#             else :\n",
    "#                 print('    ', w.text, len(w.particles), end=\":\")\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_conda)",
   "language": "python",
   "name": "conda_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
