{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Trainer\n",
      "Init DocResolver\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import pycor\n",
    "import pycor.scoring as scoring\n",
    "from pycor.res import CollocationResolver\n",
    "\n",
    "docsize = 3000\n",
    "\n",
    "training_data_dir = \"../../data\"\n",
    "data_dir = \"../samples\"\n",
    "outputpath = \"../../output/\" + str(docsize) + \"/\"\n",
    "model_path = outputpath + \"model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.7\n",
      "Loading Training Data - size: 3000\n",
      "100>200>300>400>Single Count: 38976\n",
      "용언 Count: 4864\n",
      "체언 Count: 18533\n",
      "Ambiguous Count: 2482\n",
      "Heads Count: 81954\n",
      "Collocations Count: 5426\n",
      "Tails Count: 601\n",
      "Clear words size: 100045\n",
      "500>600>Single Count: 40487\n",
      "용언 Count: 5606\n",
      "체언 Count: 21180\n",
      "Ambiguous Count: 2404\n",
      "Heads Count: 135648\n",
      "Collocations Count: 10604\n",
      "Tails Count: 701\n",
      "Clear words size: 100005\n",
      "700>800>900>1000>\n",
      "Single Count: 39763\n",
      "용언 Count: 6013\n",
      "체언 Count: 23024\n",
      "Ambiguous Count: 2492\n",
      "Heads Count: 178394\n",
      "Collocations Count: 14513\n",
      "Tails Count: 756\n",
      "Clear words size: 100056\n",
      "1100>1200>Single Count: 41826\n",
      "용언 Count: 5989\n",
      "체언 Count: 24333\n",
      "Ambiguous Count: 2423\n",
      "Heads Count: 217033\n",
      "Collocations Count: 22387\n",
      "Tails Count: 795\n",
      "Clear words size: 101156\n",
      "1300>1400>1500>Single Count: 40929\n",
      "용언 Count: 6348\n",
      "체언 Count: 26095\n",
      "Ambiguous Count: 2271\n",
      "Heads Count: 252751\n",
      "Collocations Count: 25839\n",
      "Tails Count: 817\n",
      "Clear words size: 100304\n",
      "1600>1700>1800>Single Count: 41353\n",
      "용언 Count: 6267\n",
      "체언 Count: 26809\n",
      "Ambiguous Count: 2372\n",
      "Heads Count: 286143\n",
      "Collocations Count: 29308\n",
      "Tails Count: 840\n",
      "Clear words size: 100827\n",
      "1900>2000>\n",
      "2100>Single Count: 40553\n",
      "용언 Count: 6453\n",
      "체언 Count: 27905\n",
      "Ambiguous Count: 2347\n",
      "Heads Count: 316373\n",
      "Collocations Count: 32643\n",
      "Tails Count: 867\n",
      "Clear words size: 101204\n",
      "2200>2300>2400>Single Count: 40499\n",
      "용언 Count: 6681\n",
      "체언 Count: 27806\n",
      "Ambiguous Count: 2355\n",
      "Heads Count: 344449\n",
      "Collocations Count: 35980\n",
      "Tails Count: 887\n",
      "Clear words size: 100008\n",
      "2500>2600>Single Count: 42933\n",
      "용언 Count: 6525\n",
      "체언 Count: 27967\n",
      "Ambiguous Count: 2391\n",
      "Heads Count: 373329\n",
      "Collocations Count: 38706\n",
      "Tails Count: 899\n",
      "Clear words size: 100245\n",
      "2700>2800>2900>Single Count: 41393\n",
      "용언 Count: 6820\n",
      "체언 Count: 29458\n",
      "Ambiguous Count: 2368\n",
      "Heads Count: 400808\n",
      "Collocations Count: 41344\n",
      "Tails Count: 911\n",
      "Clear words size: 100356\n",
      "3000>\n",
      "Single Count: 16800\n",
      "용언 Count: 3441\n",
      "체언 Count: 15459\n",
      "Ambiguous Count: 972\n",
      "Heads Count: 409515\n",
      "Collocations Count: 42252\n",
      "Tails Count: 917\n",
      "Clear words size: 42279\n",
      "Trained  3000 files : ellapsed time 543,023 ms.\n"
     ]
    }
   ],
   "source": [
    "print(pycor.version())\n",
    "\n",
    "resolver = CollocationResolver()\n",
    "pycor.addresolver(resolver)\n",
    "\n",
    "# pycor.setscorefunction(scoring.alt_scorepair)\n",
    "\n",
    "pycor.train(training_data_dir, pattern=\"*.txt\", limit=docsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "간디에 간디에  0.8359023595446756 [] set()\n",
      "간디에::set():0\n"
     ]
    }
   ],
   "source": [
    "word = pycor.resolveword('간디에', debug=True)\n",
    "\n",
    "print(word.bestpair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model to ../../output/3000/model\n",
      "Save  ../../output/3000/model/heads.csv   소요시간: 2.684\n",
      "Save  ../../output/3000/model/tails.csv   소요시간: 0.014\n",
      "Save  ../../output/3000/model/collocations.csv   소요시간: 0.223\n",
      "Clear Heads: 89139 remains.\n"
     ]
    }
   ],
   "source": [
    "pycor.savemodel(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model from ../../output/3000/model\n",
      "Load  ../../output/3000/model/heads.csv   소요시간: 5.407\n",
      "Load  ../../output/3000/model/tails.csv   소요시간: 0.012\n"
     ]
    }
   ],
   "source": [
    "pycor.loadmodel(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 []  하늘 ['JKO']  나는 []  꿈 ['JKO']  꾸었다 []  \n",
      "나는 []  하늘 ['JKO']  나는 []  새를 []  보았다 []  \n",
      "가 ['JX-SO']  세월 ['JKB-WZ']  가 ['JX-SO']  실 []  \n",
      "어디 ['JKB-TT|AS|BY']  갈 []  것인가 ['JX-SO']  아직 []  정하 ['EFO']  못했다 []  \n",
      "이해 ['JKS']  가 ['JX-SO']  상황 ['JKP']  \n",
      "고양 ['ETM', 'JKP']  동물 ['JX-SO']  가축 ['JKP']  \n",
      "고양 ['ETM', 'JKP']  지역 ['JX-SO']  서울 []  서북 []  쪽에 []  있다 []  \n",
      "고양이 ['JKS']  목 ['JKO']  축이 ['EFN']  \n",
      "산양 ['ETM', 'JKP']  짐승 ['JX-SO']  쉽게 []  보 ['ETN']  어렵다 []  \n",
      "산양 ['JX-SO']  높은 []  산 []  암벽 []  위에 []  살 ['ETN']  때문이다 []  \n",
      "모 ['ETM', 'JKP']  말 ['JKO']  못들 ['EFN', 'EPT-pp']  \n",
      "모 ['ETM', 'JKP']  말 ['JKO']  못들 ['EFN', 'EPT-pp']  \n",
      "모이라 ['JKS']  하는 []  말 ['JKO']  못들 ['EFN', 'EPT-pp']  \n",
      "폼페 ['ETM', 'JKP']  도 ['ETM', 'EPH']  화산재 ['JKB-TO']  묻혔다 []  \n",
      "역시 []  내 ['JKS']  원하는 []  바다 []  \n",
      "바 ['ETM', 'EFN']  아름답 ['EFN', 'ADJ|V+IRB']  \n",
      "오로라 ['ETM']  자연현상 ['JX-SO']  아름답다 []  \n",
      "오로 ['ETM']  자연현상 ['JKP']  \n",
      "문제 ['JX-SO']  길 ['JKP']  \n",
      "꽃게 ['JX-SO']  맛있 ['EFN', 'V']  \n",
      "내게 ['JX-SO']  말하지 []  마라 []  \n",
      "참게 ['JX-SO']  맛있 ['EFN', 'V']  \n",
      "지금 ['JX-SO']  인심 ['JKS']  후한 []  시대 ['JKS']  아 ['EFN']  \n",
      "후한 []  시대 []  사람 ['JKP']  \n"
     ]
    }
   ],
   "source": [
    "words_array, tags_array = pycor.trimfile(data_dir+\"/02_ambiguous.txt\")\n",
    "\n",
    "for row in range(len(words_array)):\n",
    "    words = words_array[row]\n",
    "    tags = tags_array[row]\n",
    "    \n",
    "    for col in range(len(words)):\n",
    "        print(words[col], tags[col], end=\"  \") \n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN이 시퀀스 모델링에 적합한 다른 요인은 매우 긴 문장 단락 심지어 문서를 포함해 다양한 텍스트 길이를 모델링할 수 있는 능력이다 . \n",
      "CNN과 달리 RNN은 무제한 컨텍스트를 포착할 수 있는 유연한 계산 step을 가진다 . \n",
      "임의의 길이의 입력값을 처리할 수 있는 이러한 능력은 RNN을 사용하는 주요 연구의 셀링포인트 가운데 하나가 됐다 . \n",
      "\n",
      "다수의 NLP 태스크는 또한 전체 문장에 대해 의미론적 모델링을 요구한다 . \n",
      "이것은 고정된 차원의 하이퍼스페이스 내에 문장의 요지 gist 를 만들어내는 것과 관련이 있다 . \n",
      "이들 인스턴스는 RNN에 의해 적절히 포착된다 . \n",
      "전체 문장이 고정된 벡터로 요약되고 나서 가변 길이의 타겟 시퀀스로 매핑되는 기계번역같은 작업에 RNN 사용이 증가했다 . \n",
      "\n",
      "RNN은 또한 시간 분산 조인트 처리 time distributed joint processing 를 위한 네트워크 지원을 제공한다 . \n",
      "품사태깅같은 시퀀스 레이블링 작업의 대부분은 이러한 domain에 기반한 것이다 . \n",
      "보다 구체적인 사용사례는 문서분류 다범주 텍스트 범주화 멀티모달 감성분석 주관성 디텍션 등이 있다 . \n",
      "\n",
      "이미 서술한 사실들은 연구자들이 RNN을 선택하는 동기가 되는 몇가지 이유다 . \n",
      "그러나 RNN이 다른 네트워크보다 우월하다고 결론을 내리는 것은 잘못된 것이다 . \n",
      "최근에 여러 연구는 CNN이 RNN보다 우월하다는 증거를 제시한다 . \n",
      "언어모델링 Langurage modeling 같은 RNN에 적합한 태스크일지라도 CNN은 RNN보다 경쟁력 있는 성능을 달성했다 . \n",
      "CNN과 RNN은 문장을 모델링할 때 다른 목적 함수 를 갖는다 . \n",
      "RNN이 경계없는 긴 문장을 생성하려고 하는 반면 CNN은 가장 중요한 n-gram을 추출하려고 한다 . \n",
      "둘다 n-gram 피처를 잡아내는 데 효율적이지만 단어 순서에 대한 민감도가 지역적으로 locally 제한되며 장기 long-term 의존성은 보통 무시된다 . \n",
      "\n",
      "\n",
      "\n",
      "경제학 經濟學 은 재화나 용역의 생산과 분배 그리고 소비와 같은 경제현상을 연구하는 사회과학의 한 분야이다 . \n",
      "economics 라는 용어는 고대 그리스어 οἰκονομία에서 유래한다 . \n",
      "경제학은 복잡한 경제 활동에서 특정한 규칙성을 발견하여 경제 현상의 원인과 결과를 탐구하고 예측하는 것을 목표로 한다 . \n",
      "이를 위해 경제학자들은 다양한 전제와 분석 대상을 설정한다 . \n",
      "그중에서도 현대 경제학에서의 주요 연구 대상은 세계의 경제 상태 개개인과 기업이 노동 소비 투자 고용 가격 등을 어떻게 결정하는 지에 대한 것이다 . \n",
      "또한 경기의 침체와 호황 개인이나 국가간에 나타나는 부의 불균형과 같은 것들도 경제학의 주요 관심 분야이다 . \n",
      "정치경제학의 한 영역으로 시작하였다 . \n",
      "\n",
      "기본적으로 경제학은 매우 거시적이고 광범위한 분야를 다루기 때문에 다른 외적 조건이 동일하다면 ceteris paribus 이라는 전제 하에서 모든 분석이 진행된다 . \n",
      "마르크스 경제학에서는 이러한 배제를 추상 abstract 이라 부른다 . \n",
      "그러나 경제학자마다 분석 대상과 전제가 다르기 때문에 그들이 주목하거나 과감히 배제해버리는 부분은 모두 각각 다르다 . \n",
      "이러한 전제와 분석대상의 차이로부터 각 경제학파들의 차이가 생겨난다 . \n",
      "이중 몇몇 유명한 경제학자들이 탐구의 대상으로 삼았던 문제들을 열거해 보면 다음과 같다 . \n",
      "국부의 성격과 원천 애덤 스미스 대지에서 수확되는 생산물의 분배를 규율하는 법칙 리카도 삶의 일상사에서 인간이 하는 행동 데번포트 이런저런 용도로 사용될 수 있는 희소한 수단과 목적사이의 관계와 관련된 인간의 행동 로빈슨 유효수요의 결정 요인 분석과 국민소득수준과 고용량 케인스 근대사회의 움직임에 관한 경제적 법칙을 규명하는 것 마르크스 \n",
      "경제학의 학파에는 고전학파 케인즈주의 제도학파 통화주의 신고전파 행동경제학 신제도주의등이 있다 . \n",
      "비주류 경제학으로는 대표적으로 포스트케인지언이 있으며 그 이외에도 신경경제학 등이 있다 . \n",
      "실증경제학은 무엇인가 를 연구하는 반면 규범경제학은 무엇이 되어야 하는가 를 연구한다 . \n"
     ]
    }
   ],
   "source": [
    "_,words_array = pycor.readfile(data_dir+\"/01_sampletext.txt\")\n",
    "\n",
    "for sentence in words_array:\n",
    "    for word in sentence:\n",
    "        print(word.text, end=\" \")\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RNN', '시퀀스', '모델링에', '적합한', '요인', '매우', '긴', '문장', '단락', '심지어', '문서를', '포함하', '다양한', '텍스트', '길이를', '모델링할', '있는', '능력']\n",
      "['CNN과', '달리', 'RNN', '무제한', '컨텍스트를', '포착할', '있는', '유연한', '계산', 'STEP', '가지']\n",
      "['임의', '길이', '입력값', '처리할', '있는', '능력', 'RNN', '사용하', '주요', '연구', '셀링포인트', '가운데', '하나', '되']\n",
      "['다수', 'NLP', '태스크', '또한', '전체', '문장에', '의미론적', '모델링', '요구하']\n",
      "['이것', '고정된', '차원', '하이퍼스페이스', '내에', '문장', '요지', 'GIST', '만들어내', '관련', '있다']\n",
      "['이들', '인스턴스', 'RNN', '적절히', '포착되']\n",
      "['전체', '문장이', '고정된', '벡터', '요약되', '나서', '가변', '길이', '타겟', '시퀀스', '매핑되', '기계번역', '작업에', 'RNN', '사용이', '증가하']\n",
      "['RNN', '또한', '시간', '분산', '조인트', '처리', 'TIME', 'DISTRIBUTED', 'JOINT', 'PROCESSING', '네트워크', '지원', '제공하']\n",
      "['품사태깅', '시퀀스', '레이블링', '작업', '대부분', 'DOMAIN', '기반한']\n",
      "['보다', '구체적', '사용사례', '문서분류', '다범주', '텍스트', '범주화', '멀티모달', '감성분석', '주관성', '디텍션', '등이', '있다']\n",
      "['이미', '서술한', '사실들', '연구자들', 'RNN', '선택하', '동', '되는', '이유']\n",
      "['그러나', 'RNN', '네트워크', '우월하', '결론', '내리', '잘못된']\n",
      "['최근에', '여', '연구', 'CNN', 'RNN', '우월하', '증거를', '제시하']\n",
      "['언어모델링', 'LANGURAGE', 'MODELING', 'RNN', '적합한', '태스크', 'CNN', 'RNN', '경쟁력', '있는', '성능', '달성하']\n",
      "['CNN과', 'RNN', '문장', '모델링할', '때', '목적', '함수', '갖']\n",
      "['RNN', '경계없', '긴', '문장', '생성하', '하는', '반면', 'CNN', '가장', '중요한', 'N-GRAM', '추출하', '한다']\n",
      "['둘', 'N-GRAM', '피처를', '잡아내', '데', '효율적', '단어', '순서에', '민감도', '지역적으로', 'LOCALLY', '제한되', '장기', 'LONG-TERM', '의존성', '보통', '무시되']\n",
      "['경제학', '經濟學', '은', '재화', '용역', '생산', '분배', '그리고', '소비와', '경제현상', '연구하', '사회과학', '한', '분야']\n",
      "['ECONOMICS', '용어', '고대', '그리스어', 'ΟἸΚΟΝΟΜΊΑ', '유래한다']\n",
      "['경제학', '복잡한', '경제', '활동에서', '특정한', '규칙성', '발견하', '경제', '현상', '원인', '결과를', '탐구하', '예측하', '목표로', '한다']\n",
      "['이를', '경제학자들', '다양한', '전제와', '분석', '대상', '설정하']\n",
      "['그중', '현대', '경제학', '주요', '연구', '대상', '세계', '경제', '상태', '개개인', '기업이', '노동', '소비', '투자', '고용', '가격', '등', '어떻', '결정하는', '지에']\n",
      "['또한', '경', '침체', '호황', '개인', '국가간', '나타나', '부', '불균형', '것들', '경제학', '주요', '관심', '분야']\n",
      "['정치경제학', '한', '영역으로', '시작하']\n",
      "['기본적으로', '경제학', '매우', '거시적', '광범위한', '분야를', '다루기', '외적', '조건이', '동일하', 'CETERIS', 'PARIBUS', '전제', '하', '분석이', '진행되']\n",
      "['마르크스', '경제학', '배제를', '추상', 'ABSTRACT', '이라', '부르']\n",
      "['그러나', '경제학자', '분석', '대상과', '전제', '다르기', '그들이', '주목하', '과감히', '배제해버리', '부분', '모두', '각각', '다르다']\n",
      "['전제와', '분석대상', '차이', '각', '경제학파들', '차이', '생겨난다']\n",
      "['이중', '몇몇', '유명한', '경제학자들', '탐구', '대상으로', '삼', '문제들', '열거하', '보', '다음', '같다']\n",
      "['국부', '성격과', '원천', '애덤', '스미스', '대지에서', '수확되', '생산물', '분배를', '규율하', '법칙', '리카도', '삶', '일상사', '인간이', '하는', '행동', '데번포트', '이런저런', '용도로', '사용될', '있는', '희소한', '수단과', '목적사이', '관계', '관련된', '인간', '행동', '로빈슨', '유효수요', '결정', '요인', '분석과', '국민소득수준', '고용량', '케인스', '근대사회', '움직임에', '경제적', '법칙', '규명하', '마르크스']\n",
      "['경제학', '학파', '고전학파', '케인즈주의', '제도학파', '통화주의', '신고전파', '행동경제학', '신제도주의등', '있다']\n",
      "['비주류', '경제학', '대표적으로', '포스트케인지언', '있', '이외', '신경경제학', '등이', '있다']\n",
      "['실증경제학', '무엇인가', '연구하', '반면', '규범경제학', '무엇이', '되어야', '하는가', '연구하']\n"
     ]
    }
   ],
   "source": [
    "words_array, tags_array = pycor.trimfile(data_dir+\"/01_sampletext.txt\")\n",
    "\n",
    "for words in words_array:\n",
    "    print(words) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readtext >>>>> \n",
      "RNN이 시퀀스 모델링에 적합한 다른 요인은 매우 긴 문장 단락 심지어 문서를 포함해 다양한 텍스트 길이를 모델링할 수 있는 능력이다 . \n",
      "CNN과 달리 RNN은 무제한 컨텍스트를 포착할 수 있는 유연한 계산 step을 가진다 . \n",
      "임의의 길이의 입력값을 처리할 수 있는 이러한 능력은 RNN을 사용하는 주요 연구의 셀링포인트 가운데 하나가 됐다 . \n",
      "다수의 NLP 태스크는 또한 전체 문장에 대해 의미론적 모델링을 요구한다 . \n",
      "이것은 고정된 차원의 하이퍼스페이스 내에 문장의 요지 gist 를 만들어내는 것과 관련이 있다 . \n",
      "이들 인스턴스는 RNN에 의해 적절히 포착된다 . \n",
      "전체 문장이 고정된 벡터로 요약되고 나서 가변 길이의 타겟 시퀀스로 매핑되는 기계번역같은 작업에 RNN 사용이 증가했다 . \n",
      "RNN은 또한 시간 분산 조인트 처리 time distributed joint processing 를 위한 네트워크 지원을 제공한다 . \n",
      "품사태깅같은 시퀀스 레이블링 작업의 대부분은 이러한 domain에 기반한 것이다 . \n",
      "보다 구체적인 사용사례는 문서분류 다범주 텍스트 범주화 멀티모달 감성분석 주관성 디텍션 등이 있다 . \n",
      "이미 서술한 사실들은 연구자들이 RNN을 선택하는 동기가 되는 몇가지 이유다 . \n",
      "그러나 RNN이 다른 네트워크보다 우월하다고 결론을 내리는 것은 잘못된 것이다 . \n",
      "최근에 여러 연구는 CNN이 RNN보다 우월하다는 증거를 제시한다 . \n",
      "언어모델링 Langurage modeling 같은 RNN에 적합한 태스크일지라도 CNN은 RNN보다 경쟁력 있는 성능을 달성했다 . \n",
      "CNN과 RNN은 문장을 모델링할 때 다른 목적 함수 를 갖는다 . \n",
      "RNN이 경계없는 긴 문장을 생성하려고 하는 반면 CNN은 가장 중요한 n-gram을 추출하려고 한다 . \n",
      "둘다 n-gram 피처를 잡아내는 데 효율적이지만 단어 순서에 대한 민감도가 지역적으로 locally 제한되며 장기 long-term 의존성은 보통 무시된다 . \n",
      "경제학 經濟學 은 재화나 용역의 생산과 분배 그리고 소비와 같은 경제현상을 연구하는 사회과학의 한 분야이다 . \n",
      "economics 라는 용어는 고대 그리스어 οἰκονομία에서 유래한다 . \n",
      "경제학은 복잡한 경제 활동에서 특정한 규칙성을 발견하여 경제 현상의 원인과 결과를 탐구하고 예측하는 것을 목표로 한다 . \n",
      "이를 위해 경제학자들은 다양한 전제와 분석 대상을 설정한다 . \n",
      "그중에서도 현대 경제학에서의 주요 연구 대상은 세계의 경제 상태 개개인과 기업이 노동 소비 투자 고용 가격 등을 어떻게 결정하는 지에 대한 것이다 . \n",
      "또한 경기의 침체와 호황 개인이나 국가간에 나타나는 부의 불균형과 같은 것들도 경제학의 주요 관심 분야이다 . \n",
      "정치경제학의 한 영역으로 시작하였다 . \n",
      "기본적으로 경제학은 매우 거시적이고 광범위한 분야를 다루기 때문에 다른 외적 조건이 동일하다면 ceteris paribus 이라는 전제 하에서 모든 분석이 진행된다 . \n",
      "마르크스 경제학에서는 이러한 배제를 추상 abstract 이라 부른다 . \n",
      "그러나 경제학자마다 분석 대상과 전제가 다르기 때문에 그들이 주목하거나 과감히 배제해버리는 부분은 모두 각각 다르다 . \n",
      "이러한 전제와 분석대상의 차이로부터 각 경제학파들의 차이가 생겨난다 . \n",
      "이중 몇몇 유명한 경제학자들이 탐구의 대상으로 삼았던 문제들을 열거해 보면 다음과 같다 . \n",
      "국부의 성격과 원천 애덤 스미스 대지에서 수확되는 생산물의 분배를 규율하는 법칙 리카도 삶의 일상사에서 인간이 하는 행동 데번포트 이런저런 용도로 사용될 수 있는 희소한 수단과 목적사이의 관계와 관련된 인간의 행동 로빈슨 유효수요의 결정 요인 분석과 국민소득수준과 고용량 케인스 근대사회의 움직임에 관한 경제적 법칙을 규명하는 것 마르크스 \n",
      "경제학의 학파에는 고전학파 케인즈주의 제도학파 통화주의 신고전파 행동경제학 신제도주의등이 있다 . \n",
      "비주류 경제학으로는 대표적으로 포스트케인지언이 있으며 그 이외에도 신경경제학 등이 있다 . \n",
      "실증경제학은 무엇인가 를 연구하는 반면 규범경제학은 무엇이 되어야 하는가 를 연구한다 . \n",
      "\n",
      "\n",
      "trim >>>>> \n",
      "RNN,시퀀스,모델링에,적합한,요인,매우,긴,문장,단락,심지어,문서를,포함하,다양한,텍스트,길이를,모델링할,있는,능력,\n",
      "CNN과,달리,RNN,무제한,컨텍스트를,포착할,있는,유연한,계산,STEP,가지,\n",
      "임의,길이,입력값,처리할,있는,능력,RNN,사용하,주요,연구,셀링포인트,가운데,하나,되,\n",
      "다수,NLP,태스크,또한,전체,문장에,의미론적,모델링,요구하,\n",
      "이것,고정된,차원,하이퍼스페이스,내에,문장,요지,GIST,만들어내,관련,있다,\n",
      "이들,인스턴스,RNN,적절히,포착되,\n",
      "전체,문장이,고정된,벡터,요약되,나서,가변,길이,타겟,시퀀스,매핑되,기계번역,작업에,RNN,사용이,증가하,\n",
      "RNN,또한,시간,분산,조인트,처리,TIME,DISTRIBUTED,JOINT,PROCESSING,네트워크,지원,제공하,\n",
      "품사태깅,시퀀스,레이블링,작업,대부분,DOMAIN,기반한,\n",
      "보다,구체적,사용사례,문서분류,다범주,텍스트,범주화,멀티모달,감성분석,주관성,디텍션,등이,있다,\n",
      "이미,서술한,사실들,연구자들,RNN,선택하,동,되는,이유,\n",
      "그러나,RNN,네트워크,우월하,결론,내리,잘못된,\n",
      "최근에,여,연구,CNN,RNN,우월하,증거를,제시하,\n",
      "언어모델링,LANGURAGE,MODELING,RNN,적합한,태스크,CNN,RNN,경쟁력,있는,성능,달성하,\n",
      "CNN과,RNN,문장,모델링할,때,목적,함수,갖,\n",
      "RNN,경계없,긴,문장,생성하,하는,반면,CNN,가장,중요한,N-GRAM,추출하,한다,\n",
      "둘,N-GRAM,피처를,잡아내,데,효율적,단어,순서에,민감도,지역적으로,LOCALLY,제한되,장기,LONG-TERM,의존성,보통,무시되,\n",
      "경제학,經濟學,은,재화,용역,생산,분배,그리고,소비와,경제현상,연구하,사회과학,한,분야,\n",
      "ECONOMICS,용어,고대,그리스어,ΟἸΚΟΝΟΜΊΑ,유래한다,\n",
      "경제학,복잡한,경제,활동에서,특정한,규칙성,발견하,경제,현상,원인,결과를,탐구하,예측하,목표로,한다,\n",
      "이를,경제학자들,다양한,전제와,분석,대상,설정하,\n",
      "그중,현대,경제학,주요,연구,대상,세계,경제,상태,개개인,기업이,노동,소비,투자,고용,가격,등,어떻,결정하는,지에,\n",
      "또한,경,침체,호황,개인,국가간,나타나,부,불균형,것들,경제학,주요,관심,분야,\n",
      "정치경제학,한,영역으로,시작하,\n",
      "기본적으로,경제학,매우,거시적,광범위한,분야를,다루기,외적,조건이,동일하,CETERIS,PARIBUS,전제,하,분석이,진행되,\n",
      "마르크스,경제학,배제를,추상,ABSTRACT,이라,부르,\n",
      "그러나,경제학자,분석,대상과,전제,다르기,그들이,주목하,과감히,배제해버리,부분,모두,각각,다르다,\n",
      "전제와,분석대상,차이,각,경제학파들,차이,생겨난다,\n",
      "이중,몇몇,유명한,경제학자들,탐구,대상으로,삼,문제들,열거하,보,다음,같다,\n",
      "국부,성격과,원천,애덤,스미스,대지에서,수확되,생산물,분배를,규율하,법칙,리카도,삶,일상사,인간이,하는,행동,데번포트,이런저런,용도로,사용될,있는,희소한,수단과,목적사이,관계,관련된,인간,행동,로빈슨,유효수요,결정,요인,분석과,국민소득수준,고용량,케인스,근대사회,움직임에,경제적,법칙,규명하,마르크스,\n",
      "경제학,학파,고전학파,케인즈주의,제도학파,통화주의,신고전파,행동경제학,신제도주의등,있다,\n",
      "비주류,경제학,대표적으로,포스트케인지언,있,이외,신경경제학,등이,있다,\n",
      "실증경제학,무엇인가,연구하,반면,규범경제학,무엇이,되어야,하는가,연구하,\n",
      "['JKS'],[],[],[],['JX-SO'],[],[],[],[],[],[],[],[],[],[],[],[],['JKP'],\n",
      "[],[],['JX-SO'],[],[],[],[],[],[],['JKO'],['EFN'],\n",
      "['JKG'],['JKG'],['JKO'],[],[],['JX-SO'],['JKO'],['JX-SO'],[],['JKG'],[],[],['JKS'],['EFN', 'EPT-pp'],\n",
      "['JKG'],[],['JX-SO'],['MAJ'],[],[],[],['JKO'],['EFN'],\n",
      "['JX-SO'],[],['JKG'],[],[],['JKG'],[],[],['JX-SO'],['JKS'],[],\n",
      "[],['JX-SO'],['JKB-TO'],[],['EFN'],\n",
      "[],[],[],['JKB-TT|AS|BY'],['EC-and'],[],[],['JKG'],[],['JKB-TT|AS|BY'],['JX-SO'],['JKG-as'],[],[],[],['EFN', 'EPT-pp'],\n",
      "['JX-SO'],['MAJ'],[],[],[],[],[],[],[],[],[],['JKO'],['EFN'],\n",
      "['JKG-as'],[],[],['JKG'],['JX-SO'],['JKB-TO'],[],\n",
      "[],['ETM+JKP', 'MM'],['JX-SO'],[],[],[],[],[],[],[],[],[],[],\n",
      "['MAG'],[],['JX-SO'],['JKS'],['JKO'],['JX-SO'],['JKS', 'ETN'],[],['EFN'],\n",
      "['MAJ'],['JKS'],['JKB-CM'],['EC-and', 'EFN'],['JKO'],['JX-SO'],[],\n",
      "[],['EC-for'],['JX-SO'],['JKS'],['JKB-CM'],['ETM', 'EFN'],[],['EFN'],\n",
      "[],[],[],['JKB-TO'],[],['EC-evenif', 'EC-evenif'],['JX-SO'],['JKB-CM'],[],[],['JKO'],['EFN', 'EPT-pp'],\n",
      "[],['JX-SO'],['JKO'],[],[],[],[],['EFN', 'EPT-pr'],\n",
      "['JKS'],['ETM', 'V'],[],['JKO'],['EC-for'],[],[],['JX-SO'],['MAG'],[],['JKO'],['EC-for'],[],\n",
      "['EFN'],[],[],['JX-SO'],[],['EC-but', 'JKP', 'MM'],[],[],['JKS'],[],[],['EC-and'],[],[],['JX-SO'],[],['EFN'],\n",
      "[],[],[],['JX'],['JKG'],['JKB-WZ'],[],['MAJ'],[],['JKO'],['ETM'],['JKG'],[],['JKP'],\n",
      "[],['JX-SO'],[],[],['JKS'],[],\n",
      "['JX-SO'],[],[],[],[],['JKO'],['JKV'],[],['JKG'],['JKB-WZ'],[],[],['JX-SO'],[],[],\n",
      "[],['JX-SO'],[],[],[],['JKO'],['EFN'],\n",
      "['JX-SO', 'JKB-FM'],[],['JKG', 'JKB-FM'],[],[],['JX-SO'],['JKG'],[],[],['JKB-WZ'],[],[],[],[],[],[],['JKO'],['EC-for'],[],[],\n",
      "['MAJ'],['JKG', 'ETN'],['JKB-WZ'],[],['JX', 'JKP'],['JKB-TO'],['JX-SO'],['JKG'],['JKB-WZ'],['JX-SO'],['JKG'],[],[],['JKP'],\n",
      "['JKG'],[],[],['EFN'],\n",
      "[],['JX-SO'],[],['EC-and', 'JKP', 'MM'],[],[],[],[],[],['EC-incase', 'EFN'],[],[],[],['JKS'],[],['EFN'],\n",
      "[],['JX-SO', 'JKB-FM'],[],[],[],[],['EFN'],\n",
      "['MAJ'],['JX'],[],[],['JKS'],[],[],['EC-or'],[],['JX-SO'],['JX-SO'],[],['MAG'],[],\n",
      "[],['JKG'],['JX-from', 'JX-from'],[],['JKG'],['JKS'],[],\n",
      "[],[],[],['JKS'],['JKG'],[],['EPT-pp', 'EPT-pp'],['JKO'],[],['EC-incase'],['JKB-WZ'],[],\n",
      "['JKG'],[],[],[],[],[],['JX-SO'],['JKG'],[],['JX-SO'],[],[],['JKG'],['JKS'],[],[],[],[],[],[],[],[],[],[],['JKG'],['JKB-WZ'],[],['JKG'],[],[],['JKG'],[],[],[],['JKB-WZ'],[],[],['JKG'],[],[],['JKO'],['JX-SO'],[],\n",
      "['JKG'],['JX-SO', 'JKB-TO'],[],[],[],[],[],[],['JKS'],[],\n",
      "[],['JX-SO', 'JKB-TT|AS|BY'],[],['JKS'],['EC-and', 'V'],['JX-SO', 'JKB-AT'],[],[],[],\n",
      "['JX-SO'],[],['ETM'],[],['JX-SO'],[],[],[],['EFN'],\n",
      "\n",
      "\n",
      " keywords >>>>> \n",
      "{RNN: 13, 경제학: 8}\n"
     ]
    }
   ],
   "source": [
    "text = ''\n",
    "\n",
    "with open(data_dir+\"/01_sampletext.txt\", 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "\n",
    "print(\"readtext >>>>> \") \n",
    "\n",
    "_,words_array = pycor.readtext(text)\n",
    "\n",
    "for sentence in words_array:\n",
    "    for word in sentence:\n",
    "        print(word.text, end=\" \")\n",
    "    print() \n",
    "    \n",
    "print(\"\\n\\ntrim >>>>> \") \n",
    "simple_words_array, tags_array = pycor.trim(text)\n",
    "\n",
    "for sentence in simple_words_array:\n",
    "    for word in sentence:\n",
    "        print(word , end=\",\")\n",
    "    print() \n",
    "\n",
    "for tags in tags_array:\n",
    "    for tag in tags:\n",
    "        print(tag , end=\",\")\n",
    "    print() \n",
    "    \n",
    "print(\"\\n\\n keywords >>>>> \") \n",
    "keywords = pycor.keywords(words_array, 0.3)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "keywords >>>>> \n",
      "{RNN: 13, 경제학: 8}\n",
      "\n",
      "sentences >>>>> \n",
      "RNN이 시퀀스 모델링에 적합한 다른 요인은 매우 긴 문장 단락 심지어 문서를 포함해 다양한 텍스트 길이를 모델링할 수 있는 능력이다 .\n",
      "CNN과 달리 RNN은 무제한 컨텍스트를 포착할 수 있는 유연한 계산 step을 가진다 .\n",
      "임의의 길이의 입력값을 처리할 수 있는 이러한 능력은 RNN을 사용하는 주요 연구의 셀링포인트 가운데 하나가 됐다 .\n",
      "이들 인스턴스는 RNN에 의해 적절히 포착된다 .\n",
      "전체 문장이 고정된 벡터로 요약되고 나서 가변 길이의 타겟 시퀀스로 매핑되는 기계번역같은 작업에 RNN 사용이 증가했다 .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keywords, sentences = pycor.abstractKeywords(words_array, 0.3, 5)\n",
    "print(\"\\n\\nkeywords >>>>> \") \n",
    "print(keywords)\n",
    "print(\"\\nsentences >>>>> \") \n",
    "lines = pycor.totexts(sentences)\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "keywords >>>>> \n",
      "{RNN: 13, 경제학: 8}\n",
      "\n",
      "sentences >>>>> \n",
      "RNN이 시퀀스 모델링에 적합한 다른 요인은 매우 긴 문장 단락 심지어 문서를 포함해 다양한 텍스트 길이를 모델링할 수 있는 능력이다 .\n",
      "CNN과 달리 RNN은 무제한 컨텍스트를 포착할 수 있는 유연한 계산 step을 가진다 .\n",
      "임의의 길이의 입력값을 처리할 수 있는 이러한 능력은 RNN을 사용하는 주요 연구의 셀링포인트 가운데 하나가 됐다 .\n",
      "이들 인스턴스는 RNN에 의해 적절히 포착된다 .\n",
      "전체 문장이 고정된 벡터로 요약되고 나서 가변 길이의 타겟 시퀀스로 매핑되는 기계번역같은 작업에 RNN 사용이 증가했다 .\n"
     ]
    }
   ],
   "source": [
    "keywords, sentences = pycor.abstract(text, 0.3, 5)\n",
    "print(\"\\n\\nkeywords >>>>> \") \n",
    "print(keywords)\n",
    "print(\"\\nsentences >>>>> \") \n",
    "lines = pycor.totexts(sentences)\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_conda)",
   "language": "python",
   "name": "conda_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
