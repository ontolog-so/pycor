{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import pycor \n",
    "from pycor import utils, korlang\n",
    "\n",
    "stopwatch = utils.StopWatch()\n",
    "\n",
    "\n",
    "docsize = 2\n",
    "model_size = 700\n",
    "outputpath = \"../../output/\" + str(model_size) + \"/\"\n",
    "model_path = outputpath + \"model/\"\n",
    "\n",
    "pycor.loadmodel(model_path)\n",
    "\n",
    "parser = korlang._trainer\n",
    "resolver = korlang._resolver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def listfiles(path):\n",
    "    result_arr = []\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in filenames:\n",
    "        full_filename = os.path.join(path, filename)\n",
    "        result_arr.append(full_filename)\n",
    "    return result_arr\n",
    "    \n",
    "files = []\n",
    "files.extend( listfiles('../samples/news') )\n",
    "files.extend( listfiles('../../data/news') )\n",
    "files.extend( listfiles('../../data/blotter') )\n",
    "files.extend( listfiles('../../data/zdnet') )\n",
    "files.extend( listfiles('../../data/ciobiz') )\n",
    "files.extend( listfiles('../../data/wiki') )\n",
    "files.extend( listfiles('../../data/NP') )\n",
    "\n",
    "print (len(files), \"files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def printKwywords(keywords, words_array):\n",
    "    print(\"===========\")\n",
    "    print(keywords)\n",
    "\n",
    "def summarizeDocument(file, rate=0.1, count=3):\n",
    "    if file.endswith(\".txt\") :\n",
    "        print(file)\n",
    "        sentence_array, words_array = parser.loadfile(file)\n",
    "        keywords = resolver.extractKeywords(words_array, rate)\n",
    "        if len(keywords) < 1:\n",
    "            rate /= 2\n",
    "            keywords = resolver.extractKeywords(words_array, rate)\n",
    "        print(\"===========\")\n",
    "        print(keywords)\n",
    "        print(\"------------\")\n",
    "        sentences = resolver.abstractDocument(keywords, words_array, count)\n",
    "        korlang.printSentences(sentences)\n",
    "        return words_array\n",
    "\n",
    "\n",
    "def summarizeDocument2(file, keywords, count=3):\n",
    "    if file.endswith(\".txt\") :\n",
    "        print(file)\n",
    "        sentence_array, words_array = parser.loadfile(file)\n",
    "        print(\"===========\")\n",
    "        print(keywords)\n",
    "        print(\"------------\")\n",
    "        sentences = resolver.abstractDocument(keywords, words_array, count)\n",
    "        dr.printSentences(sentences)\n",
    "        return words_array\n",
    "\n",
    "\n",
    "def extractKw(file, rate=0.1):\n",
    "    if file.endswith(\".txt\") :\n",
    "        print(file)\n",
    "        sentence_array, words_array = parser.loadfile(file)\n",
    "        keywords = resolver.extractKeywords(words_array,rate)\n",
    "        printKwywords(keywords, words_array)\n",
    "\n",
    "\n",
    "stopwatch.start()\n",
    "\n",
    "for file in files[:docsize]:\n",
    "#     extractKw(file, 0.05)\n",
    "    summarizeDocument(file, 0.05, 3)\n",
    "\n",
    "# extractKw(\"../data/NP/mp-all.txt\",0.1)\n",
    "# summarizeDocument(\"../data/NP/mp-all.txt\",0.1)\n",
    "# summarizeDocument(\"../data/wiki/%EB%8B%A8%EB%B0%B1%EC%A7%88.txt\",0.1)\n",
    "# summarizeDocument(\"samples/01_sampletext.txt\")\n",
    "# summarizeDocument(\"../data/wiki/%EC%A0%95%EB%B3%B4%20%EC%9D%B4%EB%A1%A0.txt\")\n",
    "\n",
    "print(\"Loading Texts: \" , stopwatch.secmilli() , \"(\", stopwatch.millisecstr(), \"ms.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_array_list = []\n",
    "\n",
    "for file in files[:4]:\n",
    "    words_array = summarizeDocument(file, 0.05, 3)\n",
    "    words_array_list.append(words_array)\n",
    "\n",
    "print(\"======== Merge News ==========\")\n",
    "sentences = resolver.mergeDocuments(words_array_list, 0.3, 6)\n",
    "\n",
    "korlang.printSentences(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_array_list = []\n",
    "\n",
    "for file in files[27:33]:\n",
    "    words_array = summarizeDocument(file, 0.05, 3)\n",
    "    words_array_list.append(words_array)\n",
    "\n",
    "print(\"======== Merge News ==========\")\n",
    "sentences = resolver.mergeDocuments(words_array_list, 0.1, 6)\n",
    "\n",
    "korlang.printSentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_conda)",
   "language": "python",
   "name": "conda_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
